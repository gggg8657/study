Unsupervised control through non-parametric discriminative rewards

About Entropy

    결정론적에 가까울수록 엔트로피는 낮다.
    순수하게 확률적으로 계산이 될 떄, 엔트로피가 높다 라고 표현한다.
    엔트로피를 높힌다 -> 어떤 액션을 취했을 때, 어떤 스테이트에 가는게 아니라, 다른 스테이트에 갈 확률도 높히겠다.
    H(X) 를 맥시마이즈, 하고 H(X|Y ) 를 미니마이즈 한다 는 H(Y) 가 미니마이즈 된다.

    어떤 액션을 취했을 때, X 라는 스테이트에 갈 확률을 낮추는 것을 미니마이즈
    즉, 결정론적인 부분을 최소화해서, 확률 적으로 계산되는 경우들의 가능성을 높히자. 

    그래서, exploration 의 가능성을 높히자.

    왜 그런가? 는 잘 모르겠다.

    state 에 대한 entropy 를 높히고, 

about analyze

    정보 이론적으로 이런 objective function을 사용하면

    어떤 효과를 얻게 된다. 

    라고 와 닿아야 해석이 된거다.

논문을 읽는법

    이런식으로 되어있구나, 라고 명쾌하게 이해하는게 중요하다.

    어떤거는 대충 그렇게 치고 넘어가자, 이렇게 하면? 이런 이전 연구가 있었다.
    라는거로 끝나는거다.

    이전 연구 많이 알아서, 뭐 논문 나중에 작성할 논문에, 제안하는 알고리즘 작성하기 위해서?
    이런 논문이 있었다 정도 알아서는 실질적인 도움이 되지 않는다.

    뭔가를 구체화를 시키고 하기 위해서는 도움이 안된다.

    즉, 논문을 읽으면서, 이렇게 하면 어떤 문제가 있겠는데?
    뭔가 새로운 문제를 발견하거나, 
    왜 이렇게 하는거지? 를 통해서, 새로운 방향성을 찾거나 할 수 있어짐.

자료 준비
    전체에 대해서 
    top down 방식으로 어떤게 문제가 있어서, 이거가 추가가 되고 이게 보완이되고
    이런식으로, 정리가 되었으면 좋겠다.
    구체적인 얘기는 다음시간에 들어봐야 하지만, 
    